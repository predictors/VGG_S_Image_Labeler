{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted 'https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/vgg_cnn_s.pkl' (ANSI_X3.4-1968) -> 'https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/vgg_cnn_s.pkl' (UTF-8)\n",
      "--2015-11-19 01:13:21--  https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/vgg_cnn_s.pkl\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.32.8\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.32.8|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 412264404 (393M) [binary/octet-stream]\n",
      "Saving to: 'vgg_cnn_s.pkl'\n",
      "\n",
      "vgg_cnn_s.pkl       100%[=====================>] 393.17M  2.11MB/s   in 3m 0s  \n",
      "\n",
      "2015-11-19 01:16:21 (2.19 MB/s) - 'vgg_cnn_s.pkl' saved [412264404/412264404]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/lasagne/recipes/pretrained/imagenet/vgg_cnn_s.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lasagne\n",
    "from lasagne.layers import InputLayer, DenseLayer, DropoutLayer\n",
    "from lasagne.layers.conv import Conv2DLayer as ConvLayer\n",
    "from lasagne.layers import MaxPool2DLayer as PoolLayer\n",
    "from lasagne.layers import LocalResponseNormalization2DLayer as NormLayer\n",
    "from lasagne.utils import floatX\n",
    "import pickle\n",
    "import io\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "\n",
    "def save_json_file(**kwargs):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Saves dictionary in path.\n",
    "    \"\"\"\n",
    "\n",
    "    dict_to_save = kwargs[\"dict_to_save\"]\n",
    "    path = kwargs[\"path\"]\n",
    "    with open(path,'wb') as fp:\n",
    "        json.dump(dict_to_save, fp)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "class ImageLabeler:\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def predictors_ai_interface(self, **kwargs):\n",
    "\n",
    "            \"\"\"\n",
    "            This is the method used by Predictors.ai to interact with the model.\n",
    "            Inputs:\n",
    "            - pipe_id (integer): id of the pipe that has to be used.\n",
    "            - input_data (dictionary): dictionary that contains the input data. The keys of the dictionary \n",
    "            correspond to the names of the inputs specified in models_definition.json for the selected pipe.\n",
    "            Each key has an associated value. For the input variables the associated value is the value\n",
    "            of the variable, whereas for the input files the associated value is its filename. \n",
    "            - input_files_dir (string): Relative path of the directory where the input files are stored\n",
    "            (the algorithm has to read the input files from there).\n",
    "            - output_files_dir (string): Relative path of the directory where the output files must be stored\n",
    "            (the algorithm must store the output files in there).\n",
    "            Outputs:\n",
    "            - output_data (dictionary): dictionary that contains the output data. The keys of the dictionary \n",
    "            correspond to the names of the outputs specified in models_definition.json for the selected pipe. \n",
    "            Each key has an associated value. For the output variables the associated value is the value\n",
    "            of the variable, whereas for the output files the associated value is its filename.  \n",
    "            \"\"\"\n",
    "\n",
    "            pipe_id = kwargs['pipe_id']\n",
    "            input_data = kwargs['input_data']\n",
    "            input_files_dir = kwargs['input_files_dir']\n",
    "            output_files_dir = kwargs['output_files_dir']\n",
    "\n",
    "            output_data = self.predict(pipe_id, input_data, input_files_dir, output_files_dir)\n",
    "\n",
    "            return output_data\n",
    "        \n",
    "\n",
    "    def load_parameters(self):\n",
    "        \n",
    "        print(\"loading parameters...\")\n",
    "\n",
    "        net = {}\n",
    "        net['input'] = InputLayer((None, 3, 224, 224))\n",
    "        net['conv1'] = ConvLayer(net['input'], num_filters=96, filter_size=7, stride=2)\n",
    "        net['norm1'] = NormLayer(net['conv1'], alpha=0.0001) # caffe has alpha = alpha * pool_size\n",
    "        net['pool1'] = PoolLayer(net['norm1'], pool_size=3, stride=3, ignore_border=False)\n",
    "        net['conv2'] = ConvLayer(net['pool1'], num_filters=256, filter_size=5)\n",
    "        net['pool2'] = PoolLayer(net['conv2'], pool_size=2, stride=2, ignore_border=False)\n",
    "        net['conv3'] = ConvLayer(net['pool2'], num_filters=512, filter_size=3, pad=1)\n",
    "        net['conv4'] = ConvLayer(net['conv3'], num_filters=512, filter_size=3, pad=1)\n",
    "        net['conv5'] = ConvLayer(net['conv4'], num_filters=512, filter_size=3, pad=1)\n",
    "        net['pool5'] = PoolLayer(net['conv5'], pool_size=3, stride=3, ignore_border=False)\n",
    "        net['fc6'] = DenseLayer(net['pool5'], num_units=4096)\n",
    "        net['drop6'] = DropoutLayer(net['fc6'], p=0.5)\n",
    "        net['fc7'] = DenseLayer(net['drop6'], num_units=4096)\n",
    "        net['drop7'] = DropoutLayer(net['fc7'], p=0.5)\n",
    "        net['fc8'] = DenseLayer(net['drop7'], num_units=1000, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "        self.output_layer = net['fc8']\n",
    "        \n",
    "        self.generate_scores_json()\n",
    "        self.generate_model_definition()\n",
    "        \n",
    "        model = pickle.load(open('vgg_cnn_s.pkl'))\n",
    "        self.classes = model['synset words']\n",
    "        self.mean_image = model['mean image']\n",
    "\n",
    "        lasagne.layers.set_all_param_values(self.output_layer, model['values'])\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def prep_image_from_file(self, filepath):\n",
    "        ext = filepath.split('.')[-1]\n",
    "        im = plt.imread(io.BytesIO(open(filepath).read()), ext)\n",
    "        # Resize so smallest dim = 256, preserving aspect ratio\n",
    "        h, w, _ = im.shape\n",
    "        if h < w:\n",
    "            im = skimage.transform.resize(im, (256, w*256/h), preserve_range=True)\n",
    "        else:\n",
    "            im = skimage.transform.resize(im, (h*256/w, 256), preserve_range=True)\n",
    "\n",
    "        # Central crop to 224x224\n",
    "        h, w, _ = im.shape\n",
    "        im = im[h//2-112:h//2+112, w//2-112:w//2+112]\n",
    "\n",
    "        rawim = np.copy(im).astype('uint8')\n",
    "\n",
    "        # Shuffle axes to c01\n",
    "        im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "\n",
    "        # Convert to BGR\n",
    "        im = im[::-1, :, :]\n",
    "\n",
    "        im = im - self.mean_image\n",
    "        return rawim, floatX(im[np.newaxis])\n",
    "\n",
    "    \n",
    "    def generate_scores_json(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculate scores.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        scores = []\n",
    "\n",
    "        score = {}\n",
    "        score[\"name\"] = \"Top 5 error rate in ILSVRC-2012\"\n",
    "        score[\"value\"] = 13.1\n",
    "        scores.append(score)\n",
    "    \n",
    "        scores_out = {}\n",
    "        scores_out[\"scores\"] = scores\n",
    "        scores_out[\"schema_version\"] = \"0.02\"\n",
    "\n",
    "        save_json_file(dict_to_save=scores_out, path=\"./scores.json\")\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def generate_model_definition(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Returns model_definition.json dictionary.\n",
    "        \"\"\"\n",
    "\n",
    "        model_definition = {}\n",
    "        model_definition[\"name\"] = \"VGG_S Image Labeler\"\n",
    "        model_definition[\"schema_version\"] = \"0.02\"\n",
    "        model_definition[\"environment_name\"] = \"python2.7.9_November19th2015\"\n",
    "        model_definition[\"description\"] = \"This predictor is based on the example for the python\" \\\n",
    "                                          \" library Lasagne available at https://github.com/Lasagne/Recipes\" \\\n",
    "                                          \"/blob/master/examples/ImageNet%20Pretrained%20Network%20(VGG_S).ipynb\" \\\n",
    "                                          \"<br /><br />\" \\\n",
    "                                          \"<b>You can find the source code of this onine demo at: \" \\\n",
    "                                          \"https://github.com/predictors/VGG_S_Image_Labeler</b>\" \\\n",
    "                                          \"<br /><br />\" \\\n",
    "                                          \"It demonstrates using a network pretrained on ImageNet for \" \\\n",
    "                                          \"classification. The model used was converted from the VGG_CNN_S model \" \\\n",
    "                                          \"(http://arxiv.org/abs/1405.3531) in Caffe's Model Zoo.\" \\\n",
    "                                          \"<br /><br />\" \\\n",
    "                                          'For details of the conversion process, see the example notebook \"Using' \\\n",
    "                                          'a Caffe Pretrained Network - CIFAR10\"'\n",
    "\n",
    "        model_definition[\"retraining_allowed\"] = False\n",
    "        model_definition[\"base_algorithm\"] = \"Convolutional Neural Network\"     \n",
    "        model_definition[\"score_minimized\"] = \"\"        \n",
    "\n",
    "        pipes = self.get_pipes()\n",
    "        model_definition[\"pipes\"] = pipes\n",
    "\n",
    "        save_json_file(dict_to_save=model_definition, path=\"./model_definition.json\")\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def get_pipes(self, **kwargs):\n",
    "\n",
    "        \"\"\"\n",
    "        Returns pipes.json dictionary.\n",
    "        \"\"\"\n",
    "\n",
    "        pipes = [ \n",
    "                    {\n",
    "                        \"id\": 0,\n",
    "                        \"action\": \"predict\",\n",
    "                        \"name\":\"One by one prediction\",\n",
    "                        \"description\": \"Please upload a png or jpg image.\",\n",
    "                        \"inputs\": [\n",
    "                            {\n",
    "                                \"name\": \"Input image\",\n",
    "                                \"type\": \"file\",\n",
    "                                \"extensions\": [\n",
    "                                    \"png\",\n",
    "                                    \"jpg\"\n",
    "                                ],\n",
    "                                \"required\": True\n",
    "                            }\n",
    "                        ],\n",
    "                        \"outputs\": [\n",
    "                            {\n",
    "                                \"name\": \"Predicted labels\",\n",
    "                                \"type\": \"variable\",\n",
    "                                \"variable_type\": \"string\"\n",
    "                            }\n",
    "                        ]\n",
    "                    },\n",
    "                ]\n",
    "\n",
    "        return pipes\n",
    "\n",
    "    \n",
    "    def predict(self, pipe_id, input_data, input_files_dir, output_files_dir):\n",
    "\n",
    "        image_filepath = input_file_path = input_files_dir + input_data['Input image']\n",
    "        try:\n",
    "            rawim, im = self.prep_image_from_file(image_filepath)\n",
    "\n",
    "            prob = np.array(lasagne.layers.get_output(self.output_layer, im, deterministic=True).eval())\n",
    "            top5 = np.argsort(prob[0])[-1:-6:-1]\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(rawim.astype('uint8'))\n",
    "            plt.axis('off')\n",
    "            labels = []\n",
    "            for n, label in enumerate(top5):\n",
    "                labels.append(\"[\" + self.classes[label] + \"]\")\n",
    "            output = {\"Predicted labels\": str(labels)[1:-1].replace(\"'\",\"\")}\n",
    "        except IOError:\n",
    "            output = {\"Predicted labels\": \"The image you uploaded cannot be read.\"}\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading parameters...\n"
     ]
    }
   ],
   "source": [
    "il = ImageLabeler()\n",
    "il.load_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Predicted labels': '[bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis], [Arabian camel, dromedary, Camelus dromedarius], [ram, tup], [ibex, Capra ibex], [triceratops]'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_id = 0\n",
    "input_files_dir = \"./\"\n",
    "output_files_dir = \"\"\n",
    "input_data = {}\n",
    "input_data[\"Input image\"] = \"kangaroo.jpg\"\n",
    "il.predictors_ai_interface(pipe_id=pipe_id, input_files_dir=input_files_dir, output_files_dir=output_files_dir, input_data=input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.setrecursionlimit(10000)\n",
    "\n",
    "# save trained model\n",
    "import cPickle as pickle\n",
    "with open(\"./ImageLabeler.pk\",'wb') as fp:\n",
    "    pickle.dump(il, fp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
